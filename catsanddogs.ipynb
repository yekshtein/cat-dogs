{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from os import environ\n",
    "version = '1.0'\n",
    "#environ['MODEL_FILE'] = 'saved_model.pb'.format(version)\n",
    "environ['MODEL_FILE'] = 'saved_model.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'MODEL_FILEPATH' environment variable\n"
     ]
    }
   ],
   "source": [
    "%nuclio env -c V3IO_USERNAME=${V3IO_USERNAME}\n",
    "%nuclio env -c V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "%nuclio env -c MODEL_FILE=${MODEL_FILE}\n",
    "%nuclio env -c MODEL_FILEPATH=/tmp/mlmodel/${MODEL_FILE}\n",
    "%nuclio env -l MODEL_FILEPATH=/User/docs/site/en/tutorials/images/saved_models/1551857232/${MODEL_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install --force tensorflow\n",
    "pip install --force tensorflow_hub\n",
    "pip install v3io_frames\n",
    "pip install dask_ml\n",
    "apt-get update && apt-get install -y wget\n",
    "mkdir -p /tmp/mlmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio cmd -c wget -O /tmp/mlmodel/${MODEL_FILE} --header \"x-v3io-session-key: ${V3IO_ACCESS_KEY}\" http://10.96.108.8:8081/users/${V3IO_USERNAME}/demos/netops/models/${MODEL_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.triggers.secs.attributes.interval to '60s'\n",
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n",
      "%nuclio: setting spec.volumes.volume.name to 'fs'\n",
      "%nuclio: setting spec.volumes.volume.flexVolume.driver to 'v3io/fuse'\n",
      "%nuclio: setting spec.volumes.volume.flexVolume.secretRef.name to 'jupyter-63mzkiyfdm-pgruh-v3io-fuse'\n",
      "%nuclio: setting spec.volumes.volumeMount.volumeMount.name to 'fs'\n",
      "%nuclio: setting spec.volumes.volumeMount.volumeMount.mountPath to '/v3io'\n",
      "%nuclio: setting spec.volumes.volumeMount.volumeMount.readOnly to False\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config \n",
    "spec.triggers.secs.attributes.interval = \"60s\"\n",
    "spec.build.baseImage = \"python:3.6-jessie\"\n",
    "spec.volumes.volume.name = \"fs\"\n",
    "spec.volumes.volume.flexVolume.driver = \"v3io/fuse\"\n",
    "spec.volumes.volume.flexVolume.secretRef.name = \"jupyter-63mzkiyfdm-pgruh-v3io-fuse\"\n",
    "spec.volumes.volumeMount.volumeMount.name = \"fs\"\n",
    "spec.volumes.volumeMount.volumeMount.mountPath = \"/v3io\"\n",
    "spec.volumes.volumeMount.volumeMount.readOnly = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import v3io_frames as v3f\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define v3io TSDB client\n",
    "client = v3f.Client('framesd:8081')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 160 # All images will be resized to 160x160\n",
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "batch_size = 32\n",
    "zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\", \n",
    "                                   fname=\"cats_and_dogs_filtered.zip\", extract=True)\n",
    "base_dir, _ = os.path.splitext(zip_file)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/User/.keras/datasets/cats_and_dogs_filtered\n",
      "/User/.keras/datasets/cats_and_dogs_filtered/validation\n"
     ]
    }
   ],
   "source": [
    "print (base_dir)\n",
    "print (validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./saved_models\")\n",
    "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
    "new_model.trainable = True\n",
    "new_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio handler\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "prediction = datagen.flow_from_directory(\n",
    "                validation_dir, # Source directory for the validation images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='binary')\n",
    "\n",
    "for item in prediction.classes:\n",
    "    print('Image is a ' + {False: 'Cat', True :'Dog'}[item])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "#print ('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "#print ('Total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                validation_dir, # Source directory for the validation images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='binary')\n",
    "\n",
    "for item in validation_generator.classes:\n",
    "    print('Image is a ' + {False: 'Cat', True :'Dog'}[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio deploy -n catsanddogs -p test1 -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "nuclio.magic.print_handler_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
